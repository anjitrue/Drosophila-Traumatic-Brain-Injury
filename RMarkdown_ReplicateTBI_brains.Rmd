---
title: "Drosophila Traumatic Brain Injury Replicate Experiment"
author: "Anji Trujillo - Professor Coon"
date: "January 14, 2020"
output: html_document
fig_caption: yes
---

```{r setup, include=FALSE}
require(knitr)
opts_knit$set(root.dir = "G:/Projects/Proteomics/DorsophilaHead_Experiment/")
knitr::opts_chunk$set(root.dir = "G:/Projects/Proteomics/DorsophilaHead_Experiment/", warning = FALSE, message = FALSE)
```

This is an R Markdown Document describing the proteomics data collected for the Drosophila Traumatic Brain Injury Project in collaboration with Professor Wassarman and Becky Katzenberger. The samples analyzed were derived from heads of Drosophila melanogaster that were fed either Food and Water or ONLY Water for 24 hours. Each time points contains a paired control and matching traumatic brain injury (TBI) sample. 

The Proteomics data was collected August 11, 2019. The initial analysis was performed September 9, 2019 on MaxQuant and searched as:  

* Drosophila (TBI + Control) on Food and Water AND Water only  


```{r install_packages, echo=FALSE}
library(readr)
library(plyr)
library(dplyr)
library(pheatmap)
library(RColorBrewer)
library(viridis)
library(pcaMethods)
library(ggplot2)
library(grid)
library(gridExtra)
library(cowplot)
library(hrbrthemes)
library(devtools)
library(e1071)
library(dplyr)
library(Mfuzz)
library(cluster)
library(yaml)
library(Rcpp)
library(pls)
library(hexbin)
library(MetaCycle)
library(EnhancedVolcano)
```

The data exploration and analysis was performed using R. A series of filters have been applied to clean the data. The following were removed: contaminants, reverse sequences, and only identified by site. Then the dataframe was subset using a 50% filter, removing protein groups that have over half of the values missing, the output will be used for imputation purposes. The following utilized protein groups that contain complete measurements across all samples. 

```{r functions, echo=FALSE}

subsetLFQ <- function(q){
  y <- q[,c("Protein.IDs", "id","Gene.names")] 
  z <- q[,grep("LFQ.intensity",names(q))]
  z[z == 0] <- NA
  x <- bind_cols(y,z)
  #how many missing values in protein groups dataframe
  print(paste("Number of missing measurements", sum(is.na(x)), " out of ", ncol(x)*nrow(x) , " equates to ", (sum(is.na(x))/(ncol(x)*nrow(x))*100) , "% of data missing from complete data set"))
  x <- x[complete.cases(x),]
  return(x)
 } 
 
remove.features.50percentcuttoff <- function (x) {
  features.missing = rowMeans(is.na(x)) 
  print(paste0("Number of protein groups that have over 50% missing measurements: ",sum(features.missing > 0.50))) 
  features.missing.50more = rownames(x)[features.missing > 0.50] 
  
  keep.features = which(features.missing <= 0.50) 
  print(paste0("Protein groups that pass the 50% filteration: ", length(keep.features)))
  names(keep.features) = keep.features 
  
  remove.features = which(features.missing > 0.50)
  print(paste0("Number of protein groups removed from dataset: ", length(remove.features)))
  names(remove.features) = remove.features
  
  filtered = x[-which(rownames(x) %in% remove.features),]
  return(filtered)
}

filter.std.plotting <- function (eset, min.std,visu=TRUE)
{
  #index <- logical(dim(exprs(eset))[1])

  tmp <- logical(dim(exprs(eset))[1])
  if (is.numeric(min.std))
  { 
    data <- exprs(eset)
      for (i in 1:length(tmp))
      {
        tmp[i]   <- sd(data[i,],na.rm=TRUE)
        #index[i]  <- ( tmp[i] > min.std)
        
      }
    index <- tmp > min.std
    index[is.na(index)] <- TRUE
    cat(paste(sum(!index),"Proteins have a standard deviation greater than ", min.std, ".\n"))
  }
  
  if (visu)
  {
    plot(sort(tmp),xlab="Ordered Hemo Proteins",ylab="Standard Deviation")
  }
  eset[index,]
}

fuzzyprep_usepreviousImputation_foldchange <- function(z)
{
  exprValues <- new("ExpressionSet", exprs = as.matrix(z))
  tmp = filter.std.plotting(exprValues, min.std = 0.1)
  #exprValues.s = standardise(exprValues)
  return(exprValues)
}
  
```


#### Load data: Drosophila (TBI + Control) on 1. Food and Water AND 2. Water only 
```{r load_data, echo=FALSE}
# Load data containing a subset of columns for the FWW dataset
proteinGroups_dros_Brain_FWW <- read.csv("I:/EAT_BackUP/Trujillo_34362342_44636349_SN_Data/P2/Complete/Projects/Proteomics/DorsophilaHead_Experiment/txt_Food_Water_Water_Together/proteinGroups_Food_Water_Water_Together.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)

# Load data containing more information on the scans and quality of identifications
proteinGroups_dros_Brain_FWW_extended <- read.csv("I:/EAT_BackUP/Trujillo_34362342_44636349_SN_Data/P2/Complete/Projects/Proteomics/DorsophilaHead_Experiment/txt_Food_Water_Water_Together/proteinGroups_Food_Water_Water_Together_20191018.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)

cat(paste0("Number of protein groups in Brain Data before any filtering of missing measurements: ", nrow(proteinGroups_dros_Brain_FWW)))

# cat(paste0("Number of protein groups in Brain Data before any filtering of missing measurements: ", nrow(proteinGroups_dros_Brain_FWW_extended)))

proteinGroups_dros_Brain_FWW <- subsetLFQ(proteinGroups_dros_Brain_FWW) 
print(paste("Number of complete proteins: ", nrow(proteinGroups_dros_Brain_FWW))) 


notPartOfExperiment <- vector()
for(i in 21:40){
  id <- paste0(".",as.character(i),"_n")
  print(id)
  notPartOfExperiment <- append(notPartOfExperiment,grep(id,colnames(proteinGroups_dros_Brain_FWW_extended)))
}

#remove samples greater than 20 
proteinGroups_dros_Brain_FWW_extended_filtered <- proteinGroups_dros_Brain_FWW_extended[,-notPartOfExperiment]
write.csv(proteinGroups_dros_Brain_FWW_extended_filtered,"I:/EAT_BackUP/Trujillo_34362342_44636349_SN_Data/P2/Complete/Projects/Proteomics/DorsophilaHead_Experiment/txt_Food_Water_Water_Together/proteinGroups_Heads_TBI_replicates_FW_20191018.csv")


proteinGroups_dros_Brain_FWW_extended_filteredagain <- subsetLFQ(proteinGroups_dros_Brain_FWW_extended) 
print(paste("Number of complete proteins: ", nrow(proteinGroups_dros_Brain_FWW_extended_filteredagain)))

```

A few notes:

* FWW refers to data set that includes samples on Food as well as samples on Water only
* FW refers to a subset of the data that includes samples on Food and water
* FWW and FW datasets are Log2 transformed. 
* Note for simplification MaxQuant identifiers for protein groups will be used in replacement of Uniprot ID or gene name.

```{r format_brains, echo=FALSE}
#log2 transform and subset only complete cases
LFQ_BrainsFWW_LOG2_complete <- log2(as.matrix(proteinGroups_dros_Brain_FWW[,grep("LFQ.intensity",names(proteinGroups_dros_Brain_FWW))[1]:ncol(proteinGroups_dros_Brain_FWW)]))


#set row names to match protein group identifer number
rownames(LFQ_BrainsFWW_LOG2_complete) <- proteinGroups_dros_Brain_FWW$id

#substitute blank before intensity.
samples_replicates <- sub(".*intensity.", "",colnames(LFQ_BrainsFWW_LOG2_complete))

#create a data frame with sample and replicate information      
df.sample.names <- data.frame(samples = samples_replicates, replicates = sub(".*_", "", samples_replicates), number = as.numeric(sub("_.*", "", samples_replicates)))

#order the sample numbers in ascending order
df.sample.names <- df.sample.names[order(df.sample.names$number),]
#sample numbers will be of type numeric
samples <- as.factor(as.numeric(sub("_n.*","", samples_replicates)))

#replace colnames
colnames(LFQ_BrainsFWW_LOG2_complete) <- samples

#order samples in ascending order
LFQ_FWW_Ordered_LOG2 <- LFQ_BrainsFWW_LOG2_complete[,order(as.numeric(as.character(colnames(LFQ_BrainsFWW_LOG2_complete))))]
#create a new data frame that is not log2 transformed
LFQ_FWW_Ordered <- 2^LFQ_FWW_Ordered_LOG2

LFQ_FWW_Ordered_LOG2_uniqueName <- LFQ_FWW_Ordered_LOG2
colnames(LFQ_FWW_Ordered_LOG2_uniqueName) <- df.sample.names$samples

sample_7_n3 <- apply(LFQ_FWW_Ordered_LOG2_uniqueName[,19:20] , 1, mean)
sample_9_n2 <- apply(LFQ_FWW_Ordered_LOG2_uniqueName[,24:25] , 1, mean)
sample_20_n3 <- apply(LFQ_FWW_Ordered_LOG2_uniqueName[,56:57] , 1, mean)

LFQ_FWW_Ordered_LOG2_uniqueName_add7920 <- cbind(LFQ_FWW_Ordered_LOG2_uniqueName[,1:20],
                                                 sample_7_n3,
                                                 LFQ_FWW_Ordered_LOG2_uniqueName[,21:24],
                                                 sample_9_n2,
                                                 LFQ_FWW_Ordered_LOG2_uniqueName[,25:57],
                                                 sample_20_n3,
                                                 LFQ_FWW_Ordered_LOG2_uniqueName[,58:ncol(LFQ_FWW_Ordered_LOG2_uniqueName)])


```



```{r FWW_stats , echo=FALSE}
#Food and Water Experiment
LFQ_FW_Ordered_LOG2 <- LFQ_FWW_Ordered_LOG2[,1:57]
LFQ_FW_Ordered_LOG2_uniqueName <- LFQ_FWW_Ordered_LOG2_uniqueName[,1:57]

#Water ONLY Experiment
LFQ_W_Ordered_LOG2 <- LFQ_FWW_Ordered_LOG2[,58:ncol(LFQ_FWW_Ordered_LOG2)]
LFQ_W_Ordered_LOG2 <- LFQ_FWW_Ordered_LOG2_uniqueName[,58:ncol(LFQ_FWW_Ordered_LOG2_uniqueName)]


#Sum up TIC of all samples for non-transformed and Log2 datasets that contain FWW samples
col_sums <- apply(LFQ_FWW_Ordered, 2, sum)
col_sums_log2 <- apply(LFQ_FWW_Ordered_LOG2,2,sum)

 plot(col_sums, type = 'n',  main = "Summed TIC (non-transformed)", sub = "Brain Samples on FW and W", ylab = "TIC", xlab = "Sample Index")
 text(col_sums, labels = colnames(LFQ_FWW_Ordered))

 plot(col_sums_log2, type = 'n',  main = "Summed TIC (Log2 transformed)", sub = "Brain Samples on FW and W", ylab = "TIC", xlab = "Sample Index")
 text(col_sums_log2, labels = colnames(LFQ_FWW_Ordered))

#Sum up all proteins to determine TIC of all samples (column wise) for only FW samples [,1:57]
col_sums_FW <- apply(LFQ_FWW_Ordered[,1:57],2,sum)
col_sums_FW_Log2 <- apply(LFQ_FW_Ordered_LOG2,2,sum)

# can be used, removed for Wassarman
plot(col_sums_FW, type = 'n',  main = "Summed TIC (non-transformed)", sub = "Brain Samples on FW", ylab = "TIC", xlab = "Sample Index")
text(col_sums_FW, labels = colnames(LFQ_FWW_Ordered[,1:57]))

#Sum up all proteins to determine TIC of all samples (column wise) for only FW samples [,58:ncol(LFQ_FWW_Ordered)]
col_sums_W <- apply(LFQ_FWW_Ordered[,58:ncol(LFQ_FWW_Ordered)],2,sum)

# can be used, removed for Wassarman
# plot(col_sums_W, type = 'n',  main = "Summed TIC (non-transformed)", sub = "Brain Samples on W", ylab = "TIC", xlab = "Sample Index")
# text(col_sums_W, labels = colnames(LFQ_FWW_Ordered[,58:ncol(LFQ_FWW_Ordered)]))

#rename the column names that have been sorted numerically
even = seq(2,20,2)
odd = seq(1,20,2)
samples_numeric <- as.numeric(colnames(LFQ_FWW_Ordered_LOG2)) #currently colnames are characters, switch to numeric

#colnames(LFQheads_LOG2) <- samples #do I need to make into numeric

# Create a meta object with all the samples information 

brain_FWW_meta <- data.frame(Samples = samples_numeric, Sample_Type=c(rep(c("Control","Control","Control","TBI","TBI", "TBI"),3), "Control","Control", "TBI", "TBI", "TBI", "Control", "Control", rep(c("TBI", "TBI", "TBI", "Control", "Control", "Control"),5), "TBI", "TBI", rep(c("Control", "Control", "TBI", "TBI"),10)), Condition = c(rep("Food&Water", 57), rep("Water", 40)))

brain_FWW_meta$hour <- c(rep("0", 6), rep("30 min",6), rep("1 hr",6), rep("2 hr",5), rep("4 hr",5), rep("6 hr",6), rep("8 hr",6), rep("12 hr",6), rep("16 hr", 6), rep("24 hr",5), rep("0",4), rep("30 min",4), rep("1 hr",4), rep("2 hr",4), rep("4 hr",4), rep("6 hr",4), rep("8 hr",4), rep("12 hr",4), rep("16 hr", 4), rep("24 hr",4))

brain_FWW_meta$replicates <- sub("\\.\\d+$", "", df.sample.names$replicates)
brain_FWW_meta$replicates <- gsub("[.]","",brain_FWW_meta$replicates)
brain_FWW_meta$unique <- apply( brain_FWW_meta[ , c(2,4,5) ] , 1 , paste , collapse = " " )
#sub("(^[^.]+[.]+).*", "\\1", brain_FWW_meta$replicates)

brain_FW_meta <- brain_FWW_meta[1:57,]

#print(brain_FWW_meta, quote = TRUE, row.names = FALSE)
#number_times = c(0, 0, (.5/24), (.5/24), (1/24), (1/24), (2/24), (2/24), 
                 # (4/24), (4/24), (6/24), (6/24), (8/24), (8/24), (12/24), (12/24), 
                 # (16/24), (16/24), (24/24), (24/24), (48/24), (48/24), (72/24), (72/24), 
                 # 7, 7, 14, 14, 21, 21, 28, 28, 35, 35)
#head_meta$time <- number_times

# write.csv(brain_FW_meta,"I:/EAT_BackUP/Trujillo_34362342_44636349_SN_Data/P2/Complete/Projects/Proteomics/DorsophilaHead_Experiment/SamplePrep_Document/proteinGroups_Heads_TBI_replicates_FW_20191018_sampleNames_meta.csv")

```

```{r, echo=FALSE}

colors <- c("#206F94", # teal
            "#F47F72", #coral
            "#75C69D", #baby green
            "#2CA8E0", #coon blue
            "#1F6F94", #darker blue
            "#5C66AF", #light purpleblue
            "#2A4093", #dark purpleblue
            "#2C9379", #dark baby green
            "#83D5F7", #light coon blue
            "#93211E", #dark red
            "#E73C25", #red
            "#81143A", #dark pink
            "#ED237A") #hot pink)

sample.colors = as.numeric(factor(brain_FWW_meta$Samples[1:57]))
mycolors <- colorRampPalette(brewer.pal(12, "Set3"))(length(unique(sample.colors)))
par(mar=c(6.5, 7.5, 1.5, 1), mgp=c(3.5, 0.8, 0), las=1)
barplot(col_sums_FW,
        main = "Summed TIC (not-transformed)",
        sub = "Brain Samples on FW",
        xaxt="n",
        ylab = "TIC",
        xlab = "Sample Index",
        ylim = c(0,7e+12),
        col = mycolors[sample.colors])

# The summed TIC for complete case proteins is compared for each sample. Within each replicate time point, the summed TIC should have low variability.

sample.colors = as.numeric(factor(brain_FWW_meta$Samples[1:57]))
mycolors <- colorRampPalette(brewer.pal(12, "Set3"))(length(unique(sample.colors)))
par(mar=c(6.5, 7.5, 1.5, 1), mgp=c(3.5, 0.8, 0), las=1)
barplot(col_sums_FW_Log2,
        main = "Summed TIC (Log2 transformed)",
        sub = "Brain Samples on FW",
        xaxt="n",
        ylab = "TIC",
        xlab = "Sample Index",
        ylim = c(0,150000),
        col = mycolors[sample.colors])

```


#### PCA plots of Brain TBI samples on Food and Water (FW)

PCA plot of all TBI brain samples (FW and W) colored by diet condition. 

PCA plot of Brain TBI samples that are on Food and Water provide a global view of the data. Each dot in the PCA is a sample where the color indicates the replicate number. Samples in sage green (replicate n1) were collected Aug 2018 and samples colored blue (replicate n3) and purple (replicate n2) were collected Aug 2019. 


```{r Average_replicates, echo=FALSE}

# Transpose LFQ dataframe. 
t_LFQ_FW_ordered_LOG2 = t(LFQ_FW_Ordered_LOG2)
# Bind with meta data 
t_LFQ_FW_ordered_LOG2 <- cbind(brain_FWW_meta[1:57,], t_LFQ_FW_ordered_LOG2)
# Change Sample from character to numeric
t_LFQ_FW_ordered_LOG2$Samples <- as.numeric(t_LFQ_FW_ordered_LOG2$Samples)

#row_sums <- apply(t_LFQ_FW_ordered_LOG2[1:3,-c(1:5)],1,sum)

# subset odd samples - Control
t_LFQ_FW_ordered_LOG2_odd <- t_LFQ_FW_ordered_LOG2[which(t_LFQ_FW_ordered_LOG2$Samples %in% odd),]
# subset even samples - TBI
t_LFQ_FW_ordered_LOG2_even <- t_LFQ_FW_ordered_LOG2[which(t_LFQ_FW_ordered_LOG2$Samples %in% even),]

# Find average intensities for each protein across batches
average_time.point <- aggregate(t_LFQ_FW_ordered_LOG2[,7:ncol(t_LFQ_FW_ordered_LOG2)],
                                list(t_LFQ_FW_ordered_LOG2$Samples), mean)

average_time.point_odd <- aggregate(t_LFQ_FW_ordered_LOG2_odd[,7:ncol(t_LFQ_FW_ordered_LOG2_odd)],
                                    list(t_LFQ_FW_ordered_LOG2_odd$Samples), mean)
rownames(average_time.point_odd) <- average_time.point_odd[,1]

average_time.point_even <- aggregate(t_LFQ_FW_ordered_LOG2_even[,7:ncol(t_LFQ_FW_ordered_LOG2_even)],
                                     list(t_LFQ_FW_ordered_LOG2_even$Samples), mean)
rownames(average_time.point_even) <- average_time.point_even[,1]


```

```{r, echo=FALSE}

pca_FW <- prcomp(t(LFQ_FW_Ordered_LOG2))

# PCA by replicate, shows batch affect by replicate
sample.colors = as.numeric(factor(brain_FWW_meta$replicates[1:57]))
plot(pca_FW$x[1:57,1:2], pch = 19, cex = 2,
     col = colors[3:5][sample.colors], 
     main = "Principle Component Analysis\n Brain TBI on Food & Water", 
     ylim = c(-20, 20), xlim = c(-20, 20), 
     xlab = "PC1 24.17%", ylab ="PC2 10.23%")
#text(pca_FW$x[,1][1:57], pca_FW$x[,2][1:57], labels = colnames(LFQ_FWW_Ordered_LOG2)[1:57])
legend("topright", legend = levels(factor(brain_FWW_meta$replicates[1:57])), pch = 16, 
       col = colors[3:5][1:length(levels(factor(brain_FWW_meta$replicates[1:57])))], y.intersp = 0.7)
```

#### Normalization using time zero. 
#### Comparing time zero for TBI and time zero for Control on Brain samples that were on Food and Water. 
Due to high variability originating from each replicate (n1, n2, n3), normalization will be important for further analysis. Note, time zero samples are available and provide a baseline. In the TBI sample, time zero, was collecting right after imposing traumatic brain injury. A control sample was also collected at time zero for each replicate.  

The following normalization will be done.
```{r normalize_time0, echo=FALSE}

# Average of both Control and TBI time 0
average_time.point_TBI_CTRL <- data.frame(colMeans(t_LFQ_FW_ordered_LOG2[1:6,7:ncol(t_LFQ_FW_ordered_LOG2)]))
average_time.point_TBI_CTRL <- t(average_time.point_TBI_CTRL)

# Add this average to the end of all the averages 
average_time.point <- rbind(average_time.point[,-c(1)],average_time.point_TBI_CTRL)

# create a new data frame for normalization
norm_FW_Log2 <- t_LFQ_FW_ordered_LOG2

# subset new data frame for odd and even 
norm_FW_Log2_odd <- t_LFQ_FW_ordered_LOG2_odd 
norm_FW_Log2_even <- t_LFQ_FW_ordered_LOG2_even


# Normalization for-loop for odd or Control samples using control time 0
for(j in 1:3) {

  for (i in 1:nrow(t_LFQ_FW_ordered_LOG2_odd)) {
    
      if(t_LFQ_FW_ordered_LOG2_odd[i,5] == paste0("n",j)){
      Mj = j
      norm_FW_Log2_odd[i,-c(1:6)] <- t_LFQ_FW_ordered_LOG2_odd[i,-c(1:6)] - t_LFQ_FW_ordered_LOG2_odd[Mj,-c(1:6)] + average_time.point[1,]
    }
  }
}


# Normalization for-loop even or TBI samples using TBI time 0
for(j in 1:3) {

  for (i in 1:nrow(t_LFQ_FW_ordered_LOG2_even)) {
    
      if(t_LFQ_FW_ordered_LOG2_even[i,5] == paste0("n",j)){
      Mj = j
      norm_FW_Log2_even[i,-c(1:6)] <- t_LFQ_FW_ordered_LOG2_even[i,-c(1:6)] - t_LFQ_FW_ordered_LOG2_even[Mj,-c(1:6)] + average_time.point[2,]
    }
  }
}


# row bind the normalization done using separate time zero and then perform PCA analysis 
mean_normalized_FW_byProtein_sepTBIandCTRL <- rbind(norm_FW_Log2_odd,norm_FW_Log2_even)

pca_FW_meanNormalized <- prcomp(mean_normalized_FW_byProtein_sepTBIandCTRL[,-c(1:6)])


```

```{r,echo=FALSE}


 pheatmap(mean_normalized_FW_byProtein_sepTBIandCTRL[1:28,-c(1:6)], 
         color = inferno(10), 
         show_colnames = FALSE,
         show_rownames = TRUE,
         scale = "column",
         #cluster_rows = FALSE,
         drop_levels = TRUE,
         main = "Mean Normalized Proteins - Controls")

 pheatmap(mean_normalized_FW_byProtein_sepTBIandCTRL[29:nrow(mean_normalized_FW_byProtein_sepTBIandCTRL),-c(1:6)], 
         color = inferno(10), 
         show_colnames = FALSE,
         show_rownames = TRUE,
         scale = "column",
         #cluster_cols = FALSE,
         drop_levels = TRUE,
         main = "Mean Normalized Proteins - TBI")

```


```{r,echo=FALSE}
##### Eucclidean clustering of Fold Change #####
mean_normalized_CTRL_clus <- hclust(dist(mean_normalized_FW_byProtein_sepTBIandCTRL[1:28,-c(1:6)], method = "euclidean"))
clusters <- cutree(mean_normalized_CTRL_clus, k=20)

par(mar = c(4,6,4,1), las  = 1, mgp = c(2.5,0.5,0), tcl =  -0.3, ps = 12)
plot(mean_normalized_CTRL_clus, label= FALSE, main = "Brain Dendogram Controls - Euclidean Distance")
rect.hclust(mean_normalized_CTRL_clus, k=10, border = "red")

# TBI clustering
mean_normalized_TBI_clus  <- hclust(dist(mean_normalized_FW_byProtein_sepTBIandCTRL[29:nrow(mean_normalized_FW_byProtein_sepTBIandCTRL),-c(1:6)], method = "euclidean"))
clusters <- cutree(mean_normalized_TBI_clus, k =20)
# 
par(mar = c(4,6,4,1), las  = 1, mgp = c(2.5,0.5,0), tcl =  -0.3, ps = 12)
plot(mean_normalized_TBI_clus, label= FALSE, main = "Brain Dendogram TBI - Euclidean Distance")
rect.hclust(mean_normalized_TBI_clus, k=10, border = "red")


```

#### PCA plot of samples that were normalized by the sample type. 
An average time zero for Control and one for TBI was applied.  After normalization all samples were analyzed by PCA. Note separation based on replicate is still a driver of variation, but there less separation between n1 replicate and n2 and n3 replicate.
```{r, echo=FALSE}
sample.colors = as.numeric(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$replicates))
par(mar=c(6.5, 7.5, 4.5, 1))
plot(pca_FW_meanNormalized$x, pch = 19, cex = 2,
     col = colors[3:5][sample.colors], 
     main = "Principle Component Analysis\n Brain TBI Normalized to Mean Protein Intensity\n on Food & Water",
     ylim = c(-20, 20), xlim = c(-20, 25), 
     xlab = "PC1 16.18%", ylab ="PC2 13.99%")
text(pca_FW_meanNormalized$x[,1], pca_FW_meanNormalized$x[,2], 
     labels = mean_normalized_FW_byProtein_sepTBIandCTRL$Samples)
legend("topright", 
       legend = levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$replicates)), 
       pch = 16, 
       col = colors[3:5][1:length(levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$replicates)))], 
       y.intersp = 0.7)

# Good code, but removed for Wassarman
# sample.colors = as.numeric(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$replicates))
#  par(mar=c(6.5, 7.5, 4.5, 1))
#  plot(pca_FW_meanNormalized$x[,1], pca_FW_meanNormalized$x[,3], pch = 19, cex = 2,
#      col = colors[3:5][sample.colors],
#      main = "Principle Component Analysis\n Brain TBI Normalized to Mean Protein Intensity\n on Food & Water",
#      ylim = c(-20, 20), xlim = c(-20, 25),
#      xlab = "PC1 16.18%", ylab ="PC3 11.62%")
# text(pca_FW_meanNormalized$x[,1], pca_FW_meanNormalized$x[,3],
#      labels = mean_normalized_FW_byProtein_sepTBIandCTRL$Samples)
# legend("topright",
#        legend = levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$replicates)),
#        pch = 16,
#        col = colors[3:5][1:length(levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$replicates)))],
       # y.intersp = 0.7)

 sample.colors = as.numeric(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$Sample_Type))
 par(mar=c(6.5, 7.5, 4.5, 1))
 plot(pca_FW_meanNormalized$x, pch = 19, cex = 2,
     col = colors[sample.colors],
     main = "Principle Component Analysis\n Brain TBI Normalized to Mean Protein Intensity\n on Food & Water",
     ylim = c(-20, 20), xlim = c(-20, 25),
     xlab = "PC1 16.18%", ylab ="PC2 13.99%")
text(pca_FW_meanNormalized$x[,1], pca_FW_meanNormalized$x[,2],
     labels = mean_normalized_FW_byProtein_sepTBIandCTRL$Samples)
legend("topright",
       legend = levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$Sample_Type)),
       pch = 16,
       col = colors[1:length(levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$Sample_Type)))],
       y.intersp = 0.7)


```

Color by time
```{r, echo=FALSE}
plot(pca_FW_meanNormalized$x, pch = 19, cex = 2,
     col = colors[as.numeric(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$hour))],
     main = "Principle Component Analysis\n Brain TBI Normalized to Mean Protein Intensity\n on Food & Water",
     ylim = c(-20, 20), xlim = c(-20, 25),
     xlab = "PC1 16.18%", ylab ="PC2 13.99%")
text(pca_FW_meanNormalized$x[,1], pca_FW_meanNormalized$x[,2],
     labels = mean_normalized_FW_byProtein_sepTBIandCTRL$hour)
legend("topright",
       legend = levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$Sample_Type)),
       pch = 16,
       col = colors[1:length(levels(factor(mean_normalized_FW_byProtein_sepTBIandCTRL$Sample_Type)))],
       y.intersp = 0.7)
```


The loadings plot describes which proteins are driving the differences in grouping in the PCA plot above. Focusing on PC2, the proteins that are driving the clustering driven replicates are in red. After further analysis, these proteins have coefficient of variations (CV) greater than 100%.
```{r, echo=FALSE}
# Loadings plot of samples normalized with separate time zero's
par(mar=c(6.5, 7.5, 4.5, 1))
plot(pca_FW_meanNormalized$rotation, 
     pch = 19, 
     cex = 2,
     col="#00000033",
     main = "Loadings Plot\n Normalized to separate time zero \n Control and TBI Samples on Food & Water") 
text(pca_FW_meanNormalized$rotation[,1][which(pca_FW_meanNormalized$rotation[,2] < -0.1)], pca_FW_meanNormalized$rotation[,2][which(pca_FW_meanNormalized$rotation[,2] < -0.1)], 
     col = "red", labels = names(pca_FW_meanNormalized$rotation[,1][which(pca_FW_meanNormalized$rotation[,2] < -0.1)]))
text(pca_FW_meanNormalized$rotation[,1][which(pca_FW_meanNormalized$rotation[,2] > 0.1)], pca_FW_meanNormalized$rotation[,2][which(pca_FW_meanNormalized$rotation[,2] > 0.1)], 
     col = "red", labels = names(pca_FW_meanNormalized$rotation[,1][which(pca_FW_meanNormalized$rotation[,2] > 0.1)]))
```


#### Coefficient of Variation for FW samples normalized to separate TBI and Control time zero

Taking normalized LFQ values for TBI and control samples, the CV distributions are explored and addressed. 

```{r cv_brains, echo=FALSE}
mean_normalized_FW_byProtein_sepTBIandCTRL_removeLOG2 <- cbind(mean_normalized_FW_byProtein_sepTBIandCTRL[,c(1:6)] ,2^(mean_normalized_FW_byProtein_sepTBIandCTRL[,-c(1:6)]))

# Aggregate the replicates and calculate the mean LFQ intensities
average_protein_sepTBIandCTRL <- aggregate(mean_normalized_FW_byProtein_sepTBIandCTRL_removeLOG2[,-c(1:6)],
                                list(mean_normalized_FW_byProtein_sepTBIandCTRL_removeLOG2$Samples), mean)
# Aggregate the replicates and calculate the stdev LFQ intensities
stdev_sepTBIandCTRL <- aggregate(mean_normalized_FW_byProtein_sepTBIandCTRL_removeLOG2[,-c(1:6)],
                                list(mean_normalized_FW_byProtein_sepTBIandCTRL_removeLOG2$Samples), sd)


cv_time.sepTBIandCTRL <- stdev_sepTBIandCTRL/average_protein_sepTBIandCTRL *100

cv_time.matrix.sepTBIandCTRL <- as.matrix(cv_time.sepTBIandCTRL[-c(1:2),-1])

cv_time.dataframe.septTBIandCTRL <- as.data.frame(t(cv_time.matrix.sepTBIandCTRL))

colnames(cv_time.dataframe.septTBIandCTRL) <- rownames(cv_time.sepTBIandCTRL[-c(1:2),])


```

Histogram of the CV values for each protein. The blue line is the mean CV value at 16.85% and black line is the median CV value at 13.12%. 

```{r, echo=FALSE}
hist(cv_time.matrix.sepTBIandCTRL,
     breaks = 100,
     main = "% CV Distribution for Normalized Proteins",
     xlab = "Coefficient of Variation (CV)",
     xlim = c(0,200),
     col= "darkmagenta")

abline(v=mean(cv_time.matrix.sepTBIandCTRL),
       col="royalblue",
       lwd=2)
abline(v=median(cv_time.matrix.sepTBIandCTRL),
       color= "red",
       lwd = 2)

boxplot(cv_time.dataframe.septTBIandCTRL)

```

For the normalized FW (Food and Water) data set (with TBI and Control Samples), the proteins with greater than 100% CV are removed. These highly variable proteins add to the variability within replicates. In total there are 90 proteins with CV greater than 100%.  

```{r CV_timePoint, echo=FALSE}

#ggplot(cv_time.point.data.frame, aes(x = `1`)) + geom_histogram(binwidth = .5 )

# Extract proteins with greater than 100 CV and append sample information
v <- vector()
row <- vector ()
sample <- vector ()
protein <- vector()
for (i in 2:ncol(cv_time.sepTBIandCTRL)) {
  if(length(which(cv_time.sepTBIandCTRL[,i] > 100)) != 0){
    v <- which(cv_time.sepTBIandCTRL[,i] > 100)
    for (j in 1:length(which(cv_time.sepTBIandCTRL[,i] > 100))) {
      row <- v[j] 
      protein <- append(colnames(cv_time.sepTBIandCTRL[i]), protein)
      sample <- append(rownames(cv_time.sepTBIandCTRL[row,]), sample)
      }
    }
  }

# create a data frame of proteins > 100% CV
cv_100_septTBIandCTRL <- data.frame("sample" = as.numeric(sample), "protein" = protein)

# Summary table form
cv_100_protein_septTBIandCTRL.table <- (table(cv_100_septTBIandCTRL))
cv_100_protein_septTBIandCTRL.id <- unique(cv_100_septTBIandCTRL$protein)


cv_100_data.frame <- data.frame()

for (i in 1:length(cv_100_protein_septTBIandCTRL.id)) {
  v <- mean_normalized_FW_byProtein_sepTBIandCTRL[,which(colnames(mean_normalized_FW_byProtein_sepTBIandCTRL) == cv_100_protein_septTBIandCTRL.id[i])]
  cv_100_data.frame <- rbind(v,cv_100_data.frame)
}

rownames(cv_100_data.frame) <- rev(cv_100_protein_septTBIandCTRL.id)
colnames(cv_100_data.frame) <- mean_normalized_FW_byProtein_sepTBIandCTRL$Samples


cv_100_meta.data.frame <- data.frame()

for (i in 1:length(cv_100_protein_septTBIandCTRL.id)) {
  v <- proteinGroups_dros_Brain_FWW[which(proteinGroups_dros_Brain_FWW$id %in% cv_100_protein_septTBIandCTRL.id[i]), c(1:3)]
  cv_100_meta.data.frame <- rbind(v,cv_100_meta.data.frame)
}

# cv_100_meta <- proteinGroups_dros_Brain_FWW_extended[which(proteinGroups_dros_Brain_FWW_extended$id %in% cv_100_protein_septTBIandCTRL.id  ),]

cv_100_protein_Log2 <- cbind(cv_100_meta.data.frame, cv_100_data.frame)
rownames(cv_100_protein_Log2) <- cv_100_protein_Log2$id

# write.csv(cv_100_protein_Log2, "G:/Projects/Proteomics/DorsophilaHead_Experiment/Routput/Brain/CV_greater100_FW_Norm_sepTBIandCTRL.csv", row.names = FALSE)


```

 

```{r , fig.cap="Heatmap of the proteins that have a CV greater than 100%, clustering by both sample and proteins. The x-axis is samples and y axis is the 90 proteins. The proteins are identified by MaxQuant id.d", echo= FALSE}

 pheatmap(cv_100_protein_Log2[,-c(1:3)], 
         color = inferno(10), 
         show_colnames = FALSE,
         show_rownames = FALSE,
         #cluster_cols = FALSE,
         scale = "row",
         drop_levels = TRUE,
         main = "Proteins with greater than 100% CV")

```

Filter proteins to only those with CV less than 100% and perfrom PCA analysis.

```{r CV_lessThan_100, echo=FALSE}
character_proteins_greater100 <- as.character(cv_100_protein_septTBIandCTRL.id)

FW_proteins_lessThan100CV <- mean_normalized_FW_byProtein_sepTBIandCTRL[,-which(colnames(mean_normalized_FW_byProtein_sepTBIandCTRL)%in% character_proteins_greater100)]

FW_proteins_lessThan100CV_noMeta <- FW_proteins_lessThan100CV[,-c(1:6)]

t_FW_proteins_lessThan100CV <- t(FW_proteins_lessThan100CV_noMeta)
colnames(t_FW_proteins_lessThan100CV) <- FW_proteins_lessThan100CV$Samples

proteins_lessThan100CV_csv <- proteinGroups_dros_Brain_FWW[which(proteinGroups_dros_Brain_FWW$id %in% rownames(t_FW_proteins_lessThan100CV)),1:3]

proteins_lessThan100CV_csv <- cbind(proteins_lessThan100CV_csv, t_FW_proteins_lessThan100CV)

colnames(proteins_lessThan100CV_csv) <- c("Uniprot.ID", "MaxQuant.ID", "Gene.names", mean_normalized_FW_byProtein_sepTBIandCTRL$unique)


df.sample.names <- df.sample.names[order(df.sample.names$number),]


#write.csv(proteins_lessThan100CV_csv, "G:/Projects/Proteomics/DorsophilaHead_Experiment/Routput/Brain/Proteins_Lessthan100CV_Norm_BrainTBI.csv", row.names = FALSE)

# PCA
pca_FW_lessThan100CV <- prcomp(FW_proteins_lessThan100CV[,-c(1:6)])

#proteins <- names(pca_FW_lessThan100CV$rotation[,1][which(pca_FW_lessThan100CV$rotation[,1] < -0.045)])

#cv_less100_meta <- proteinGroups_dros_Brain_FWW[which(proteinGroups_dros_Brain_FWW$id == "4849"),]
```

PCA plots of proteins with CV's less than 100. These proteins will be moved down the analysis pipeline.
```{r, echo=FALSE}
sample.colors = as.numeric(factor(FW_proteins_lessThan100CV$replicates))
par(mar=c(6.5, 7.5, 4.5, 1))
plot(pca_FW_lessThan100CV$x, pch = 19, cex = 2,
     col = colors[3:5][sample.colors], 
     ylim = c(-20,20),
     xlim = c(-20,20),
     main = "Principle Component Analysis\n Proteins with Less than 100% CV\n Control and TBI Samples on Food & Water", 
     xlab = "PC1 19.05%", ylab ="PC2 14.47%")
text(pca_FW_lessThan100CV$x[,1], pca_FW_lessThan100CV$x[,2], labels = FW_proteins_lessThan100CV$Samples)
legend("topright", legend = levels(factor(FW_proteins_lessThan100CV$replicates)), pch = 16, 
       col = colors[3:5][1:length(levels(factor(FW_proteins_lessThan100CV$replicates)))], y.intersp = 0.7)

sample.colors = as.numeric(factor(FW_proteins_lessThan100CV$Sample_Type))
par(mar=c(6.5, 7.5, 4.5, 1))
plot(pca_FW_lessThan100CV$x, pch = 19, cex = 2,
     col = colors[sample.colors], 
     ylim = c(-20,20),
     xlim = c(-20,20),
     main = "Principle Component Analysis\n Proteins with Less than 100% CV\n Control and TBI Samples on Food & Water", 
     xlab = "PC1 19.05%", ylab ="PC2 14.47%")
text(pca_FW_lessThan100CV$x[,1], pca_FW_lessThan100CV$x[,2], labels = FW_proteins_lessThan100CV$Samples)
legend("topright", legend = levels(factor(FW_proteins_lessThan100CV$Sample_Type)), pch = 16, 
       col = colors[1:length(levels(factor(FW_proteins_lessThan100CV$Sample_Type)))], y.intersp = 0.7)
```

The loading's plot shows proteins driving the separation by sample type (i.e., either TBI or Controls). 
Note these proteins are centralized around zero on both the x and y axis. 
``` {r, echo=FALSE}
# Loadings plot of samples with proteins less than 100% CV
par(mar=c(6.5, 7.5, 4.5, 1))
plot(pca_FW_lessThan100CV$rotation, 
     pch = 19, 
     cex = 2,
     col="#00000033",
     ylim = c(-0.2, 0.1), 
     xlim = c(-0.10, 0.15),
     main = "Loadings Plot\n Proteins with Less than 100% CV\n Control and TBI Samples on Food & Water") 
# text(pca_FW_lessThan100CV$rotation[,1][which(pca_FW_lessThan100CV$rotation[,1] < -0.045)], pca_FW_lessThan100CV$rotation[,2][which(pca_FW_lessThan100CV$rotation[,1] < -0.045)], 
#      col = "red", labels = names(pca_FW_lessThan100CV$rotation[,1][which(pca_FW_lessThan100CV$rotation[,1] < -0.045)]))
# text(pca_FW_lessThan100CV$rotation[,1][which(pca_FW_lessThan100CV$rotation[,1] > 0.045)], pca_FW_lessThan100CV$rotation[,2][which(pca_FW_lessThan100CV$rotation[,1] > 0.045)], 
#      col = "red", labels = names(pca_FW_lessThan100CV$rotation[,1][which(pca_FW_lessThan100CV$rotation[,1] > 0.045)]))

# bin<-hexbin(pca_FW_lessThan100CV$rotation[,1], pca_FW_lessThan100CV$rotation[,2], xbins=40)
# my_colors=colorRampPalette(rev(brewer.pal(11,'Spectral')))) 
# 
# par(mar=c(6.5, 7.5, 4.5, 1))
# plot(bin, colramp=my_colors,  main = "Loadings Plot\n Proteins with Less than 100% CV\n Control and TBI Samples on Food & Water")


``` 

```{r, echo=FALSE}

df_t_FW_proteins_lessThan100CV <- as.data.frame(t_FW_proteins_lessThan100CV)
colnames(df_t_FW_proteins_lessThan100CV) <- rownames(brain_FW_meta)

hist(t_FW_proteins_lessThan100CV[,12:13])
hist(t_FW_proteins_lessThan100CV[,42:44])

# What is distribution of p-values for t.test stats
hist(t_FW_proteins_lessThan100CV[,12:13],
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1))


```


#### PLSDA

What proteins are driving the separation between Controls and TBI? A PLSDA will answer this question.
```{r plsda, echo=FALSE}
FW_proteins_lessThan100CV_matrix <- as.matrix(FW_proteins_lessThan100CV_noMeta)

treatment_plsda_less100 <- plsr(as.numeric(FW_proteins_lessThan100CV$Sample_Type) ~ FW_proteins_lessThan100CV_matrix, method = "oscorespls", ncomp =  4)
summary(treatment_plsda_less100)

treatment_plsda_time_less100 <- plsr(as.numeric(FW_proteins_lessThan100CV$hour) ~ FW_proteins_lessThan100CV_matrix, method = "oscorespls", ncomp =  4)
summary(treatment_plsda_time_less100)
```

##### Data has been saved in .Rdata file. Can continue data anlysis from here

```{r, echo=FALSE}
save(proteinGroups_dros_Brain_FWW, 
     LFQ_FWW_Ordered_LOG2_uniqueName, 
     brain_FWW_meta,
     brain_FW_meta,
     t_LFQ_FW_ordered_LOG2,
     t_LFQ_FW_ordered_LOG2_odd,
     t_LFQ_FW_ordered_LOG2_even,
     average_time.point,
     average_time.point_odd,
     average_time.point_even,
     average_time.point_TBI_CTRL,
     colors,
     pca_FW,
     mean_normalized_FW_byProtein_sepTBIandCTRL,
     pca_FW_meanNormalized,
     mean_normalized_FW_byProtein_sepTBIandCTRL_removeLOG2,
     average_protein_sepTBIandCTRL,
     stdev_sepTBIandCTRL,
     cv_time.sepTBIandCTRL,
     cv_time.matrix.sepTBIandCTRL,
     cv_time.dataframe.septTBIandCTRL,
     cv_100_septTBIandCTRL,
     cv_100_protein_Log2,
     FW_proteins_lessThan100CV,
     FW_proteins_lessThan100CV_noMeta,
     t_FW_proteins_lessThan100CV,
     proteins_lessThan100CV_csv,
     pca_FW_lessThan100CV,
     FW_proteins_lessThan100CV_matrix,
     treatment_plsda_less100,
     file = "C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/ReplicteTBI_brains_formatted.Rdata")

save(LFQ_FWW_Ordered_LOG2_uniqueName_add7920,
     brain_FWW_meta,
     file = "C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/FWW_TBIreplicates_brains.Rdata")

load("P:/EAT_backup/CoonLab/.Rproj.user/Drosophila-Traumatic-Brain-Injury/ReplicteTBI_brains_formatted.Rdata")

```

```{r, echo=FALSE}
library(RColorBrewer)
n <- 20
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
pie(rep(1,n), col=sample(col_vector, n))

library(RColorBrewer)
brewer.pal(11, "BrBG")

library(randomcoloR)
 palette <- distinctColorPalette(n)

```

```{r, echo=FALSE}
sample.colors = as.numeric(factor(FW_proteins_lessThan100CV$Sample_Type))
time.colors = as.numeric(factor(FW_proteins_lessThan100CV$hour))
plot(treatment_plsda_less100$scores, 
     #pch = 19,  
     pch = c(1,4)[sample.colors],
     cex = 2,
     xlim = c(-8,8),
     yaxt = "n",
     #col = colors[sample.colors],
     col = "black",
     main = "PLSDA of Food and Water Samples")
axis(side = 2, las = 2, mgp = c(3, 0.75, 0))
text(treatment_plsda_less100$scores[,1],
          treatment_plsda_less100$scores[,2],
          as.character(FW_proteins_lessThan100CV$hour),
          col =  palette[time.colors],
          pos = 4, cex = 1)
legend("topleft", legend = levels(factor(FW_proteins_lessThan100CV$Sample_Type)), pch = c(1,4), col = "black") #colors[1:length(levels(factor(FW_proteins_lessThan100CV$Sample_Type)))])
```



```{r, echo=FALSE}
sample.colors = as.numeric(factor(FW_proteins_lessThan100CV$Sample_Type))
time.colors = as.numeric(factor(FW_proteins_lessThan100CV$hour))
plot(treatment_plsda_less100$scores, 
     #pch = 19,  
     pch = c(1,4)[sample.colors],
     cex = 2,
     xlim = c(-8,8),
     yaxt = "n",
     #col = colors[sample.colors],
     col = "black",
     main = "PLSDA of Food and Water Samples")
axis(side = 2, las = 2, mgp = c(3, 0.75, 0))
text(treatment_plsda_less100$scores[,1],
          treatment_plsda_less100$scores[,2],
          as.character(FW_proteins_lessThan100CV$hour),
          col =  palette[time.colors],
          pos = 4, cex = 1)
legend("topleft", legend = levels(factor(FW_proteins_lessThan100CV$Sample_Type)), pch = c(1,4), col = "black") #colors[1:length(levels(factor(FW_proteins_lessThan100CV$Sample_Type)))])
```


```{r, echo=FALSE}
# extract the MaxQuant id's for plsda top 25 leading proteins
plsda_first25_id <- as.numeric(names(rev(treatment_plsda_less100$loadings[order(-abs(treatment_plsda_less100$loadings[,1])),1][1:25])))

# gene name conversion from id
plsda_gene.name <- proteinGroups_dros_Brain_FWW_extended$Gene.names[which(proteinGroups_dros_Brain_FWW_extended$id %in% plsda_first25_id)]

#Prepare PLSDA dataframe for sharing
plsda_first25_meta <- proteinGroups_dros_Brain_FWW_extended[which(proteinGroups_dros_Brain_FWW_extended$id %in% plsda_first25_id),c(1:8, 799)]

# reorder proteins to match the dotchart plot above
plsda_first25_meta <- plsda_first25_meta[match(rev(plsda_first25_id), plsda_first25_meta$id),]

# write CSV file
# write.csv(plsda_first25_meta, "H:/Projects/Proteomics/TBI/PLSDa_lessthan100CV_TBIn3_FW_First25meta.csv") 

# use the MaxQuant id as the "names" for the genes
names(plsda_gene.name) <- proteinGroups_dros_Brain_FWW_extended$id[which(proteinGroups_dros_Brain_FWW_extended$id %in% plsda_first25_id)]
# order the genes in the same order as the dotchart orders the proteins 
plsda_gene.name <- as.vector(plsda_gene.name[as.character(plsda_first25_id)])

dotchart(rev(treatment_plsda_less100$loadings[order(-abs(treatment_plsda_less100$loadings[,1])),1][1:25]), 
         pch = 19,
         labels = plsda_gene.name,
         main = "First 25 Portein Groups driving Component 1 separation",
         color = "#5C66AF",
         xlab = "Component 1 Loadings")

dotchart(rev(treatment_plsda_less100$loadings[order(-abs(treatment_plsda_less100$loadings[,1])),1][26:50]),
         pch = 19,
         main = "Next 25 Portein Groups driving Component 1 separation",
         color = "#5C66AF",
         xlab = "Component 1 Loadings")
```

Extract the names of the top 50 proteins driving the differences between TBI and Control Samples.
```{r, echo=FALSE}

PLSDA_loadings <- treatment_plsda_less100$loadings[order(-abs(treatment_plsda_less100$loadings[,1])),1]

# Take top 50 proteins that are driving differences
proteins_driving_TBIandCtrl <- rev(treatment_plsda_less100$loadings[order(-abs(treatment_plsda_less100$loadings[,1])),1][1:50])

# Change names to numeric
proteins_driving_TBIandCtrl_numeric <- as.numeric(names(proteins_driving_TBIandCtrl))

proteins_driving_TBIandCtrl_meta <- proteinGroups_dros_Brain_FWW[which(proteinGroups_dros_Brain_FWW$id %in% names(proteins_driving_TBIandCtrl)),1:3]

proteins_driving_TBIandCtrl_intensities <- t_FW_proteins_lessThan100CV[which(rownames(t_FW_proteins_lessThan100CV)  %in% as.character(proteins_driving_TBIandCtrl_meta$id)),]

#Save in a csv
#write.csv(proteins_driving_TBIandCtrl_meta, "G:/Projects/Proteomics/DorsophilaHead_Experiment/Routput/Brain/MeanNormProteins_PLSDA_BrainTBI.csv", row.names = FALSE)

```

Heatmaps of the top 50 proteins provided by PLSDA. 

```{r,echo=FALSE}
scaleRYG <- colorRampPalette(c("red","black","darkgreen"), space = "rgb")(31)

 pheatmap(proteins_driving_TBIandCtrl_intensities[,1:28], 
         color = scaleRYG,
         scale = "row",
         show_colnames = TRUE,
         show_rownames = FALSE,
         cluster_cols = FALSE,
         drop_levels = TRUE,
         main = "PLSDA Top 50 Proteins - Controls")

 pheatmap(proteins_driving_TBIandCtrl_intensities[,29:57], 
         color = scaleRYG,
         scale = "row",
         show_colnames = TRUE,
         show_rownames = FALSE,
         cluster_cols = FALSE,
         drop_levels = TRUE,
         main = "PLSDA Top 50 Proteins - TBI")
 
```



Creating time plots in base R for tracking abundance of a single protein across the time. 
```{r TimePoint.Plots, echo=FALSE}
# Aggregate all proteins across the replicates to produce average protein intensities
average_time.point_lessThan100CV <- aggregate(FW_proteins_lessThan100CV[,7:ncol(FW_proteins_lessThan100CV)],
                                list(FW_proteins_lessThan100CV$Samples), mean)

std_time.point_lessThan100CV <- aggregate(FW_proteins_lessThan100CV[,7:ncol(FW_proteins_lessThan100CV)],
                                list(FW_proteins_lessThan100CV$Samples), sd)

# Calculate the number of samples in each time point
numberOfSamples <- FW_proteins_lessThan100CV[,7:ncol(FW_proteins_lessThan100CV)] %>% count(FW_proteins_lessThan100CV$Samples)
# Calculate standard error
std_time.point_lessThan100CV <- std_time.point_lessThan100CV[,-1]
std.error.point_lessThan100CV <- std_time.point_lessThan100CV
for(i in 1:ncol(std_time.point_lessThan100CV)){
  std.error.point_lessThan100CV[,i] <- std_time.point_lessThan100CV[,i]/sqrt(numberOfSamples$n)
}

t_average_time.point_lessThan100CV <- t(average_time.point_lessThan100CV[,-1])
colnames(t_average_time.point_lessThan100CV) <- average_time.point_lessThan100CV[,1]

t_std_time.point__lessThan100CV <- t(std_time.point_lessThan100CV[,-1])
colnames(t_std_time.point__lessThan100CV) <- std_time.point_lessThan100CV[,1]

# Aggregate proteins across the replicates to produce median protein intensities
median_time.point_lessThan100CV <- aggregate(FW_proteins_lessThan100CV_noMeta,
                                list(FW_proteins_lessThan100CV$Samples), median)

# Reduced brain FW meta dataframe that includes information for only sample type removing replicate information
brain_FW_meta_reduced <-FW_proteins_lessThan100CV[!duplicated(FW_proteins_lessThan100CV$Samples),1:6]

# To brain FW meta dataframe add numeric hours and also fraction of 24 hours
brain_FW_meta_reduced$hour.numeric <- rep(c(0,0.5,1,2,4,6,8,12,16,24),2)
brain_FW_meta_reduced$RelativeDay.numeric <- rep(c(0, 0.02, 0.04, 0.08, 0.17, 0.25, 0.33, 0.50, 0.67, 1.00),2)

brain_FW_meta$hour.numeric <- c(rep(0, 6), rep(0.5,6), rep(1,6), rep(2,5), rep(4,5), rep(6,6), rep(8,6), rep(12,6), rep(16, 6), rep(24,5))
brain_FW_meta$RelativeDay.numeric <- c(rep(0, 6), rep(0.02,6), rep(0.04,6), rep(0.08,5), rep(0.17,5), rep(0.25,6), rep(0.33,6), rep(0.50,6), rep(0.67, 6), rep(1.00,5))

# Create new object for time and labels for x-axis time
Times <- brain_FW_meta_reduced$hour.numeric[1:10]
labels_hours <- c("0","0.5","1","2","4","6","8","12","16","24")

brain_FW_meta_reduced_ordered <- brain_FW_meta_reduced[order(brain_FW_meta_reduced$Samples),]

brain_FW_meta_avg <- cbind(brain_FW_meta_reduced_ordered,average_time.point_lessThan100CV[,-1])
colnames(brain_FW_meta_avg) <- c(colnames(brain_FW_meta_reduced_ordered),colnames(average_time.point_lessThan100CV[,-1]))

# TimeSeries plot for average aggregate dataframe
n = n
x = average_time.point_lessThan100CV[,-1]
s = std.error.point_lessThan100CV

timeSeries_protein_plot <- function(n,x,s){
  even_timepoints <- x[even,which(colnames(x) == n)]
  odd_timepoints <- x[odd,which(colnames(x) == n)]
  
  even_std_timepoints <- s[even,which(colnames(s) == n)]
  odd_std_timepoints <- s[odd,which(colnames(s) == n)]
  
  even_std_timepoints_minus <- c(even_timepoints[1], even_timepoints[2:length(even_timepoints)]-(even_std_timepoints[2:length(even_std_timepoints)]))
  
  even_std_timepoints_plus <- c(even_timepoints[1], even_timepoints[2:length(even_timepoints)]+(even_std_timepoints[2:length(even_std_timepoints)]))
  
  odd_std_timepoints_minus <- c(odd_timepoints[1], odd_timepoints[2:length(odd_timepoints)]-(odd_std_timepoints[2:length(odd_std_timepoints)]))
  
  odd_std_timepoints_plus <- c(odd_timepoints[1], odd_timepoints[2:length(odd_timepoints)]+(odd_std_timepoints[2:length(odd_std_timepoints)]))
  
  if(min(even_std_timepoints_minus) < min(odd_std_timepoints_minus)){
    minimum_y_Intensity <- min(even_std_timepoints_minus)
  }else{
    minimum_y_Intensity <- min(odd_std_timepoints_minus)
  }
  
  if(max(even_std_timepoints_plus) > max(odd_std_timepoints_plus)){
    max_y_Intensity <- max(even_std_timepoints_plus)
  }else{
    max_y_Intensity <- max(odd_std_timepoints_plus)
  }

  par(mar = c(4,6,4,1), las  = 1, mgp = c(2.5,0.5,0), tcl =  -0.3, ps = 12)

  plot(Times, even_timepoints,
       ylim = c(23.5, 25.5),#c(minimum_y_Intensity,max_y_Intensity),
       xlab = "Time (Hours)", ylab = paste("Average Log2(Intensity)"),  
       #pcex=2, 
       type = "b,c",
       pch = 19,
       lty = 2,
       main = paste(n,"-", Gene.name$Gene.names, " ", Gene.name$Uniprot.ID),
       xaxt = "n")
  points(Times, odd_timepoints, type = "b,c", pch = 19, col = "red")
  #lines(Times,odd_timepoints, col = "red") 
  axis(1,Times, labels = labels_hours)
  legend("topright", legend = levels(factor(brain_FW_meta_reduced$Sample_Type)), 
         lty = 1, col = c("red","black"))
  
  
  arrows(Times, even_std_timepoints_plus, Times, even_std_timepoints_minus, length=0.05, angle=90, code=3)
   
  arrows(Times, odd_std_timepoints_plus, Times, odd_std_timepoints_minus, length=0.05, angle=90, code=3, color = "red")
}



# Data search for a with Uniprot.ID, extracting gene 
Gene <- proteins_lessThan100CV_csv[which(proteins_lessThan100CV_csv$MaxQuant.ID == 4109),3]
Gene.name <- proteins_lessThan100CV_csv[which(proteins_lessThan100CV_csv$Gene.names == "Rel"),]
Gene.name <- proteins_lessThan100CV_csv[which(proteins_lessThan100CV_csv$Gene.names == "Obp56g"),]
Gene.name <- proteins_lessThan100CV_csv[which(proteins_lessThan100CV_csv$Gene.names == "COX8"),]
Gene.name <- proteins_lessThan100CV_csv[grep("Drs",proteins_lessThan100CV_csv$Gene.names),]
Gene.name <- proteins_lessThan100CV_csv[which(proteins_lessThan100CV_csv$Gene.names == "Gpdh"),]
Gene.name <- proteins_lessThan100CV_csv[grep("A4VA49",proteins_lessThan100CV_csv$Uniprot.ID),]


protein_id <- Gene.name$MaxQuant.ID
n <- protein_id
timeSeries_protein_plot(n,average_time.point_lessThan100CV[,-1],std.error.point_lessThan100CV)
# timeSeries_protein_plot(n,median_time.point_lessThan100CV) #or median_time.point_lessThan100CV


ggplot(brain_FW_meta_avg, aes(x= hour.numeric, y=brain_FW_meta_avg[,which(colnames(brain_FW_meta_avg) == protein_id)], group = Sample_Type)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin=brain_FW_meta_avg[,which(colnames(brain_FW_meta_avg) == protein_id)]-s[,which(colnames(s) == protein_id)], ymax=brain_FW_meta_avg[,which(colnames(brain_FW_meta_avg) == protein_id)]+s[,which(colnames(s) == protein_id)]),
                alpha = 0.2,
                width = 0,
                size= 10,
                color= "#6D696F")+
    theme_light()+
    labs(title = paste(n,"-", Gene.name$Gene.names, " ", Gene.name$Uniprot.ID),
       x = "Time (hr)", y = "Log2(Intensity)")
```

#### T.test
Calculate p.values from a t.test and create a dataframe for each time point. 
```{r t.test, echo=FALSE}
# use apply function to calculate the p.value from a t.test that looks at TBI samples and coordinated controls.
# use the tryCatch() to run function and output NA where it can not perform t.test.
t.test_30.min <- apply(cbind(t_FW_proteins_lessThan100CV[,32:34], t_FW_proteins_lessThan100CV[,4:6]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_1.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,35:37], t_FW_proteins_lessThan100CV[,7:9]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_2.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,38:40], t_FW_proteins_lessThan100CV[,10:11]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_4.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,41:43], t_FW_proteins_lessThan100CV[,12:13]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_6.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,44:46], t_FW_proteins_lessThan100CV[,14:16]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_8.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,47:49], t_FW_proteins_lessThan100CV[,17:19]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_12.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,50:52], t_FW_proteins_lessThan100CV[,20:22]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_16.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,53:55], t_FW_proteins_lessThan100CV[,23:25]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})
t.test_24.hr <- apply(cbind(t_FW_proteins_lessThan100CV[,56:57], t_FW_proteins_lessThan100CV[,26:28]),1,function(x) {tryCatch(t.test(x[1:3], x[4:6])$p.value,error = function(e){NA})})

# concatonate dataframes
t.test_TBI <- data.frame(Time.30.min = as.numeric(t.test_30.min), 
                       Time.1.hr = as.numeric(t.test_1.hr), 
                       Time.2.hr = as.numeric(t.test_2.hr), 
                       Time.4.hr = as.numeric(t.test_4.hr),
                       Time.6.hr = as.numeric(t.test_6.hr),
                       Time.8.hr = as.numeric(t.test_8.hr),
                       Time.12.hr = as.numeric(t.test_12.hr),
                       Time.16.hr = as.numeric(t.test_16.hr),
                       Time.24.hr = as.numeric(t.test_24.hr))
row.names(t.test_TBI) <- row.names(t_FW_proteins_lessThan100CV)

# Transform dataframe into a matrix for plotting purposes
t.test_TBI.matrix <- as.matrix(t.test_TBI)
# Adjust p.values using "hochberg" method
t.test_TBI.matrix.adjusted <- p.adjust(t.test_4.hr, method = "hochberg")

# What is distribution of p-values for t.test stats
hist(t.test_TBI.matrix,
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

abline(v=0.05,
       col="royalblue",
       lwd=2)

# boxplot to look at individual timepoints
boxplot(t.test_TBI.matrix)

# Summary provides quantiles and the range of p.values
summary(t.test_TBI.matrix)
summary(t.test_30.min)

# Table provides the number of significant values in matrix
table(t.test_TBI.matrix < 0.05)
table(t.test_4.hr < 0.05)

```

#### ANOVA
Anova calculation on top 50 proteins, averaged time points, and individual time points. 
```{r anvoa, echo=FALSE}
# Anova analysis for samples, create separate data frames for the anova output 
anova.df_top50 <- data.frame(id = as.numeric(), 
                       Anova.p.Samply_Type = as.numeric(), 
                       Anova.p.time = as.numeric(), 
                       Anova.p.Samply_Type.Time = as.numeric(),
                       na = as.character(), 
                       Loading = as.numeric())

anova.df_allproteins <- data.frame(id = as.numeric(), 
                       Anova.p.Samply_Type = as.numeric(), 
                       Anova.p.time = as.numeric(), 
                       Anova.p.Samply_Type.Time = as.numeric(),
                       na = as.character(), 
                       Loading = as.numeric())

anova.df_averagedProteins <- data.frame(id = as.numeric(), 
                       Anova.p.Samply_Type = as.numeric(), 
                       Anova.p.time = as.numeric(), 
                       Anova.p.Samply_Type.Time = as.numeric(),
                       na = as.character(), 
                       Loading = as.numeric())

# Transpose aggregated averaged protein intensities for those with CV less than 100
t_average_time.point_lessThan100CV <- t(average_time.point_lessThan100CV[,-1])
# rename colNames
colnames(t_average_time.point_lessThan100CV) <- average_time.point_lessThan100CV$Group.1

# t_median_time.point_lessThan100CV <- t(median_time.point_lessThan100CV[,-1])
# colnames(t_median_time.point_lessThan100CV) <- median_time.point_lessThan100CV$Group.1
```

Heatmap of Averaged Time Points for proteins that have CV less than 100
```{r,echo=FALSE}

scaleRYG <- colorRampPalette(c("red","black","darkgreen"), space = "rgb")(31)

 pheatmap(t_average_time.point_lessThan100CV, 
         color = scaleRYG, 
         show_colnames = TRUE,
         show_rownames = FALSE,
         scale = "row",
         drop_levels = TRUE,
         main = "Averaged Protein Intensities")


```


Apply anova for to top 50 proteins, averaged time points, and individual time points.

```{r, echo=FALSE}

# Create a for loop for the anova analysis on each protein in PLSDA top 50
for(i in 1:nrow(proteins_driving_TBIandCtrl_meta)){
  n <- proteins_driving_TBIandCtrl_meta$id[i]
  
  aov_LFQ_lessThan100CV_top50 <-aov(t_average_time.point_lessThan100CV[which(rownames(t_average_time.point_lessThan100CV)==n),] ~  brain_FW_meta_reduced$Sample_Type * brain_FW_meta_reduced$hour.numeric)
  
  anova.df_top50[i,] <- c(n,summary(aov_LFQ_lessThan100CV_top50)[[1]][["Pr(>F)"]],proteins_driving_TBIandCtrl[as.character(n)][[1]])
}

# Create a for loop for the anova analysis for all protein
for(i in 1:nrow(t_FW_proteins_lessThan100CV)){
  n <- as.numeric(rownames(t_FW_proteins_lessThan100CV)[i])
  
  aov_LFQ_lessThan100CV_all <- aov(t_FW_proteins_lessThan100CV[which(rownames(t_FW_proteins_lessThan100CV)==n),] ~  brain_FW_meta$Sample_Type * brain_FW_meta$hour.numeric)
  
  anova.df_allproteins[i,] <- c(n,summary(aov_LFQ_lessThan100CV_all)[[1]][["Pr(>F)"]],PLSDA_loadings[as.character(n)][[1]])
}

# Create a for loop for the anova analysis for averaged time points
for(i in 1:nrow(t_average_time.point_lessThan100CV)){
  n <- as.numeric(rownames(t_average_time.point_lessThan100CV)[i])
  
  aov_LFQ_lessThan100CV_averaged <- aov(t_average_time.point_lessThan100CV[which(rownames(t_average_time.point_lessThan100CV)==n),] ~  brain_FW_meta_reduced_ordered$Sample_Type * brain_FW_meta_reduced_ordered$hour.numeric)
  
  anova.df_averagedProteins[i,] <- c(n,summary(aov_LFQ_lessThan100CV_averaged )[[1]][["Pr(>F)"]],PLSDA_loadings[as.character(n)][[1]])
}

# Summary of anova statistics
summary(aov_LFQ_lessThan100CV_top50)
summary(aov_LFQ_lessThan100CV_all)
summary(aov_LFQ_lessThan100CV_averaged)

table(anova.df_allproteins$Anova.p.Samply_Type < 0.05)

hist(anova.df_top50$Anova.p.Samply_Type,
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

abline(v=0.05,
       col="royalblue",
       lwd=2)

p1<- ggplot(data = anova.df_top50, aes(x=Anova.p.Samply_Type)) +
  geom_histogram(color="black",
                 fill="#8a238b", 
                 binwidth=.01,  
                 alpha = 0.8,  
                 position="identity")+
  ylim(0, 6)+
  theme_light()
  
p2 <- ggplot(data = anova.df_top50, aes(x=Anova.p.time)) +
  geom_histogram(color="black", 
                 fill="#8a238b", 
                 binwidth=.01, 
                 alpha = 0.8, 
                 position="identity") +
  ylim(0, 6) +
  theme_light()

p3 <- ggplot(data = anova.df_top50, aes(x=Anova.p.Samply_Type.Time)) +
  geom_histogram(color="black", 
                 fill="#8a238b", 
                 binwidth=.01, 
                 alpha = 0.8, 
                 position="identity") +
  ylim(0, 6) +
  theme_light()

ml <- plot_grid(p1,p2,p3, ncol = 1)
ggsave("G:/Projects/Proteomics/DorsophilaHead_Experiment/Figures/Brains_anova_top50.pdf", ml)

```

```{r,echo=FALSE}
hist(anova.df_allproteins$Anova.p.Samply_Type,
          breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

hist(anova.df_allproteins$Anova.p.time,
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

hist(anova.df_allproteins$Anova.p.Samply_Type.Time,
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")


p1<- ggplot(data = anova.df_allproteins, aes(x=Anova.p.Samply_Type)) +
  geom_histogram(color="black",
                 fill="#c79ae2", 
                 binwidth=.01,  
                 alpha = 0.8,  
                 position="identity")+
  ylim(0, 150)+
  theme_light()
  
p2 <- ggplot(data = anova.df_allproteins, aes(x=Anova.p.time)) +
  geom_histogram(color="black", 
                 fill="#c79ae2", 
                 binwidth=.01, 
                 alpha = 0.8, 
                 position="identity") +
  ylim(0, 150) +
  theme_light()

p3 <- ggplot(data = anova.df_allproteins, aes(x=Anova.p.Samply_Type.Time)) +
  geom_histogram(color="black", 
                 fill="#c79ae2", 
                 binwidth=.01, 
                 alpha = 0.8, 
                 position="identity") +
  ylim(0, 150) +
  theme_light()

ml <- plot_grid(p1,p2,p3, ncol = 1)
ggsave("G:/Projects/Proteomics/DorsophilaHead_Experiment/Figures/Brainsp2.pdf", ml)
  
```

```{r,echo=FALSE}

hist(anova.df_averagedProteins$Anova.p.Samply_Type,
          breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

hist(anova.df_averagedProteins$Anova.p.time,
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

hist(anova.df_averagedProteins$Anova.p.Samply_Type.Time,
     breaks = 100,
     main = "Distribution of p-values across time points",
     xlab = "p-value",
     xlim = c(0,1),
     col= "darkmagenta")

p1<- ggplot(data = anova.df_averagedProteins, aes(x=Anova.p.Samply_Type)) +
  geom_histogram(color="black",
                 fill="#cf60f3", 
                 binwidth=.01,  
                 alpha = 0.8,  
                 position="identity")+
  ylim(0, 150)+
  theme_light()
  
p2 <- ggplot(data = anova.df_averagedProteins, aes(x=Anova.p.time)) +
  geom_histogram(color="black", 
                 fill="#cf60f3", 
                 binwidth=.01, 
                 alpha = 0.8, 
                 position="identity") +
  ylim(0, 150) +
  theme_light()

p3 <- ggplot(data = anova.df_averagedProteins, aes(x=Anova.p.Samply_Type.Time)) +
  geom_histogram(color="black", 
                 fill="#cf60f3", 
                 binwidth=.01, 
                 alpha = 0.8, 
                 position="identity") +
  ylim(0, 150) +
  theme_light()

ml <- plot_grid(p1,p2,p3, ncol = 1)
ggsave("G:/Projects/Proteomics/DorsophilaHead_Experiment/Figures/Brains_anova_averagedProteins.pdf", ml)
# matching_id <- which(LFQheads_complete$id %in% df$id)
# matching_proteins_genes <- LFQheads_complete[matching_id,c(1:3)]
# 
# pls_top_proteins <- merge(matching_proteins_genes,df, by.y= "id")

#write.csv(pls_top_proteins, file = "G:/Projects/Proteomics/DorsophilaHead_Experiment/Routput/Brain/20190325pls_top_protein_gene_id_aov_Brain_completeCase.csv", row.names = FALSE)

# for(i in 1:length(ranked_pls_loading1)){
#   n = pls_top_proteins[i,1]
#   
#   pdf(paste("G:/Projects/Proteomics/DorsophilaHead_Experiment/Figures/Brains/",n,"_timeseriesplot.pdf"), useDingbats = FALSE)
#   timeSeries_protein_plot(n)
#   dev.off()
# }


# #individual anova calculations 
# anova1 <- aov(LFQheads_LOG2[which(rownames(LFQheads_LOG2)==4034),] ~  head_meta$Sample_Type * head_meta$time)
# summary(anova1)
# 
# anova5606 <- aov(LFQheads_LOG2[which(rownames(LFQheads_LOG2)==5606),] ~  head_meta$Sample_Type * head_meta$time)
# summary(anova5606)
# 
# 
# anova2535 <- aov(LFQheads_LOG2[which(rownames(LFQheads_LOG2)==2535),] ~  head_meta$Sample_Type * head_meta$time)
# summary(anova2535)

```


```{r, echo=FALSE}
# Extract aggregated averaged Controls and aggregated average TBI samples
Controls_TbI_averaged_LessThan100CV <- t_average_time.point_lessThan100CV[,odd]
TBI_averaged_LessThank100CV <- t_average_time.point_lessThan100CV[,even]
# Calculate averaged FC
FC_TBI_CTRL_averaged_LessThan100CV <- TBI_averaged_LessThank100CV - Controls_TbI_averaged_LessThan100CV




 TBI_CTRL_LessThan100CV_timepoint <- mean_normalized_FW_byProtein_sepTBIandCTRL[c(1:9,29:37),-c(1:6)]
# rownames(TBI_CTRL_LessThan100CV_first3timepoints) <- mean_normalized_FW_byProtein_sepTBIandCTRL$unique[c(1:9,29:37)]
# 
# 
# TBI_CTRL_LessThan100CV_first3timepoints[10:18,]-TBI_CTRL_LessThan100CV_first3timepoints[1:9,]
# t_FC_TBI_CTRL_LessThan100CV_first3timepoints <- t(FC_TBI_CTRL_LessThan100CV_first3timepoints)

colnames(Controls_TbI_averaged_LessThan100CV) <- c("0","0.5","1","2","4","6","8","12","16","24")
colnames(TBI_averaged_LessThank100CV) <- c("0","0.5","1","2","4","6","8","12","16","24")
colnames(FC_TBI_CTRL_averaged_LessThan100CV) <- c("time.0",colnames(t.test_TBI.matrix))

```


```{r, echo=FALSE}
hist(t_FC_TBI_CTRL_LessThan100CV_first3timepoints,
     breaks = 100,
     main = "Fold Change of Averaged Intensities",
     xlab = "Fold Change relative to Control",
     xlim = c(-2,2),
     col= "darkmagenta")

 pheatmap(t_FC_TBI_CTRL_LessThan100CV_first3timepoints, 
         color = inferno(10), 
         show_colnames = TRUE,
         show_rownames = FALSE,
         drop_levels = TRUE,
         main = "FC of Proteins with greater than 100% CV")

 pheatmap(FC_TBI_CTRL_averaged_LessThan100CV[,1:3], 
         color = inferno(10), 
         show_colnames = TRUE,
         show_rownames = FALSE,
         drop_levels = TRUE,
         main = "FC of Proteins with greater than 100% CV") 
 
```


```{r, echo=FALSE}
FC_timeSeries_protein_plot <- function(n){
  FC_timepoints <- FC_TBI_CTRL_averaged_LessThan100CV[which(rownames(FC_TBI_CTRL_averaged_LessThan100CV) == n),]

    if(abs(min(FC_timepoints)) < max(FC_timepoints)){
        max_y_Intensity <- max(FC_timepoints)
      }else{
        max_y_Intensity <- abs(min(FC_timepoints))
      }
    if(max(FC_timepoints) > abs(min(FC_timepoints))){
        min_y_Intensity <- -abs(max(FC_timepoints))
      }else{
        min_y_Intensity <- min(FC_timepoints)
        }
  
    # minimum_y_Intensity <- min(FC_timepoints)
    # 
    # max_y_Intensity <- max(FC_timepoints)

  
  #par(mfrow = c(1,2))
  #layout(matrix(c(1,1), 1, 2, byrow = TRUE), widths=c(2,1), heights=c(1,2))
  par(mar = c(4,6,4,1), las  = 1, mgp = c(2.5,0.5,0), tcl =  -0.3, ps = 12)
  #plot for hours
  plot(Times, FC_timepoints,
       ylim = c(min_y_Intensity,max_y_Intensity),
       xlab = "Time (Hours)", ylab = paste("Fold Change TBI Intensity relative to Control ",n,")"),  
       pcex=2, 
       type = "b,c",
       pch = 19,
       lty = 2,
       main = paste(n,"-", Gene.name$Gene.names, " ", Gene.name$Uniprot.ID),
       xaxt = "n")
  axis(1,Times, labels = labels_hours)
}

FC_timeSeries_protein_plot(n)

Controls_TbI_averaged_LessThan100CV_id <- cbind(rownames(Controls_TbI_averaged_LessThan100CV), Controls_TbI_averaged_LessThan100CV)
TBI_averaged_LessThank100CV_id <- cbind(rownames(TBI_averaged_LessThank100CV), TBI_averaged_LessThank100CV)
FC_TBI_CTRL_averaged_LessThan100CV_id <- cbind(rownames(FC_TBI_CTRL_averaged_LessThan100CV), FC_TBI_CTRL_averaged_LessThan100CV)

colnames(Controls_TbI_averaged_LessThan100CV_id) <- c("Uniprot.ID","0","0.5","1","2","4","6","8","12","16","24")
colnames(TBI_averaged_LessThank100CV_id) <- c("Uniprot.ID","0","0.5","1","2","4","6","8","12","16","24")
colnames(FC_TBI_CTRL_averaged_LessThan100CV_id) <- c("Uniprot.ID","0","0.5","1","2","4","6","8","12","16","24")


```

#### MetaCycle
```{r, echo=FALSE}
#Write a table for meta2d analysis
write.table(FC_TBI_CTRL_averaged_LessThan100CV_id, file="C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/FC_CONTROLS_TBI_averagedBrain_LessThan100CV.txt",
            sep="\t", quote=FALSE, row.names=FALSE)

meta2d(infile="C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/FC_CONTROLS_TBI_averagedBrain_LessThan100CV.txt", filestyle="txt",outdir="C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/example_Drosophila/", timepoints=c(0,0.5,1,2,4,6,8,12,16,24),
       cycMethod="LS", outIntegration="noIntegration")


# Individual replicate analysis data
Controls_EachRep_LessThan100CV <- mean_normalized_FW_byProtein_sepTBIandCTRL[1:28,]
TBI_EachRep_LessThan100CV <- mean_normalized_FW_byProtein_sepTBIandCTRL[29:nrow(mean_normalized_FW_byProtein_sepTBIandCTRL),]

t_Controls_EachRep_LessThan100CV <- t(Controls_EachRep_LessThan100CV[,-c(1:6)])
colnames(t_Controls_EachRep_LessThan100CV) <- Controls_EachRep_LessThan100CV$Samples
t_Controls_EachRep_LessThan100CV <- cbind(rownames(t_Controls_EachRep_LessThan100CV),t_Controls_EachRep_LessThan100CV)
colnames(t_Controls_EachRep_LessThan100CV) <- c("Uniprot.ID", colnames(t_Controls_EachRep_LessThan100CV[,-1]))

write.table(t_Controls_EachRep_LessThan100CV, file="IndivControls_LessThan100CV.txt",
            sep="\t", quote=FALSE, row.names=FALSE)

meta2d(infile="IndivControls_LessThan100CV.txt", filestyle="txt",outdir="example_Drosophila", timepoints= c(rep(c(0,0.5,1),each=3), rep(c(2,4), each=2),rep(c(6,8,12,16,24),each=3)),cycMethod="LS", outIntegration="noIntegration")


```

Clustering will be implemnted on the proteomics data set that that has been organized such that control samples are the first and TBI samples are following.

Prior to fuzzy clustering the variation for each protein plotted. 
```{r mfuzz_completeCases, echo=FALSE}

z = imputed_hemo_reorder # change accordingly to use in mfuzzy setup funtions

exprValues.s_bayesian <- fuzzyprep_usepreviousImputation(z)
```


```{r coexpression_Relish ,echo=FALSE}
# save(Brains_coexp, 
#      file = "C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/Correlation_Proteins_TBIBrain_Replicates123.Rdata")
# 
# Brains_coexp <- cor(FW_proteins_lessThan100CV_matrix)

load("C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/Correlation_Proteins_TBIBrain_Replicates123.Rdata")

filter_row <- rowSums(abs(Brains_coexp) > 0.7 & Brains_coexp != 1) > 0

pdf("C:/Users/etrujillo2/Documents/Projects/.Rproj.user/Drosophila-Traumatic-Brain-Injury/heatmap_coexp.pdf", height= 50, width = 50)
pheatmap(Brains_coexp[filter_row, filter_row])
dev.off()

# filter_coexp <- abs(Brains_coexp) > 0.6
# table(filter_coexp)[2]^(1/2)

# hist(Brains_coexp)
# 
# Brains_coexp[filter_coexp]

filter_coexpression <- Brains_coexp[filter_row, filter_row]
relish_coexpression <- filter_coexpression[which(rownames(filter_coexpression) == 4109),]

hist(relish_coexpression)
filter_coexp_rel <- abs(relish_coexpression) > 0.6

relish_coexpression <- relish_coexpression[filter_coexp_rel]
names(relish_coexpression)

for(i in 1:length(names(relish_coexpression))){
    MaxQuant_id <- names(relish_coexpression)[i]

    Gene <- proteins_lessThan100CV_csv[which(proteins_lessThan100CV_csv$MaxQuant.ID == MaxQuant_id),3]

    x <- FW_proteins_lessThan100CV_matrix[,which(colnames(FW_proteins_lessThan100CV_matrix) == 4109)]
    y <- FW_proteins_lessThan100CV_matrix[,which(colnames(FW_proteins_lessThan100CV_matrix) == MaxQuant_id)]

  plot(x,y,
       col= "red",
       pch = 16,
       main = paste("Co-expression analysis\n Relish vs ",Gene),
       xlab = "Relish", ylab = Gene)
  
}



```